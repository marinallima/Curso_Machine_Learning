# -*- coding: utf-8 -*-
"""Introdução a Machine Learning Classificação_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19w8mdj1w8bQ4ROx2UuluyQ2XeChjcm_R
"""

import pandas as pd

uri = "https://gist.githubusercontent.com/guilhermesilveira/2d2efa37d66b6c84a722ea627a897ced/raw/10968b997d885cbded1c92938c7a9912ba41c615/tracking.csv"
dados = pd.read_csv(uri)
dados.head()

x = dados[["home","how_it_works","contact"]]
y = dados[["bought"]]    #Somente o que comprou
y.head()

"""Para modificar as nomeações em inglês que já estamos utilizando, usaremos uma funcionalidade do Pandas que possibilita a renomeação das colunas: dados.rename(columns). Em seguida, passaremos mapa, um dicionário do Python em que declaramos qual será o nome das respectivas colunas:"""

mapa = { 
    "home" : "principal",
    "how_it_works" : "como_funciona",
    "contact" : "contato",
    "bought" : "comprou"
}
dados = dados.rename(columns = mapa)

x = dados[["principal","como_funciona","contato"]]
x.head()

y = dados[["comprou"]]
y.head()

"""Agora que temos x e y separados, devemos nos questionar: devemos treinar os algorítimos com todos os dados? Se fizermos isso, não teremos o que testar, pois dessa forma a máquina já terá as respostas corretas previamente, sendo incapaz de prever dados fora desse conjunto. De alguma maneira, precisamos sempre separar os dados de treino e os de teste para não enviesarmos os resultados produzidos."""

dados.shape

"""Veremos que em nosso arquivo há 99 linhas e 4 colunas. Separaremos em média 25% para testar o algorítimo, e o restante (cerca de 75% dos dados) para o treinamento. Portanto, para treino_x, coletaremos os primeiros 75 elementos (treino_x = x[:75]). Podemos utilizar treino_x.shape para verificar se o número de elementos está de fato correto:"""

treino_x = x[:75]
treino_y = y[:75]
teste_x = x[75:]
teste_y = y[75:]


print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

"""Para rodar e treinar o algoritmo: Usando o sklearn.svm importaremos LinearSVC, e treinaremos o modelo com os dados treino_x e treino_y."""

from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
import numpy as np

modelo = LinearSVC()
modelo.fit(treino_x, np.ravel(treino_y))
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

from sklearn.model_selection import train_test_split

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size =0.25)
print(treino_x.shape)
print(teste_x.shape)

from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

modelo = LinearSVC()
modelo.fit(treino_x, np.ravel(treino_y))
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

"""# Usando a biblioteca para separar Treino e Teste"""

from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

modelo = LinearSVC()
modelo.fit(treino_x, np.ravel(treino_y))
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

"""Mas esse resultado é um pouco estranho, não? Após uma verificação, perceberemos que não parece existir nada de errado no código. Porém, o executarmos novamente, teremos resultados variáveis, como 96%, 92% e até 100% novamente.

Isso ocorre porque o algorítimo train_test_split, por padrão, realiza aleatoriamente a separação de dados de treino e teste. Desse modo, todas as vezes que ele é executado podemos ter um resultado diferente.

Então como podemos fazer com que o nosso experimento seja replicável?

Precisaremos definir um número inicial para os algorítimos de geração de números aleatórios. Esse número inicial é chamado SEED, e nesse caso usaremos o número 20. Em seguida, definiremos para o train_test_split o uso do random_state = SEED.
"""

from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

SEED = 20

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED, test_size = 0.25)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

modelo = LinearSVC()
modelo.fit(treino_x, np.ravel(treino_y))
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

treino_y.value_counts()

teste_y.value_counts()

"""Se dividirmos 47 por 27 teremos 1,74. Portanto, para cada pessoa que comprou o produto, temos duas que não compraram. Já no teste temos 19 dividido por 6, que totaliza 3,1 - três pessoas que não compraram para cada uma que comprou.

Isso significa que a separação entre os dados de treino e teste não está proporcional de acordo com as nossas categorias, o que é bastante arriscado. Por exemplo, se treinarmos apenas com pessoas que não compraram o produto, o algorítimo só saberá que pessoas não compram e esse será o seu palpite padrão pois ele nunca aprendeu que usuários de fato compram o produto.

Portanto, é importante que a proporção dos nossos dados seja proporcional. Para isso,, inseriremos mais um argumento na separação de dados (train_test_split): o stratify = y, que irá estratificar os dados proporcionalmente de acordo com y.
"""

from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

SEED = 20

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y,
                                                         random_state = SEED, test_size = 0.25,
                                                         stratify = y)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

modelo = LinearSVC()
modelo.fit(treino_x, np.ravel(treino_y))
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)



treino_y.value_counts()

teste_y.value_counts()

